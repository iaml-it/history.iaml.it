<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8" />
    <title>Reinforcement Learning 1 - The Basics | Italian Association for Machine Learning</title>
    <meta content="GravCMS"  />
<meta content="The Italian Association for Machine Learning (IAML) is a not-for-profit organization with the purpose of promoting knowledge of machine learning in all aspects of the Italian public life, from universities to enterprises and IT professionals."  />
<meta property="og:title" content="Reinforcement Learning 1 - The Basics | IAML.it"  />
<meta property="og:image" content="https://iaml.it/blog/reinforcement-learning-1/markovchain.png"  />
<meta property="og:url" content="https://iaml.it/reinforcement-learning-1/"  />
<meta property="og:description" content="In this article, we will cover part of the theoretical foundations of reinforcement learning, starting with Markov Decision Processes (MDPs) and value functions. These will give us a foundation for treating reinforcement learning problems in general."  />
    <meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <link rel="icon" type="image/png" href="/user/themes/deliver/images/favicon.png" />

	<!-- Global site tag (gtag.js) - Google Ads: 774709547 --> <script async src="https://www.googletagmanager.com/gtag/js?id=AW-774709547"></script> <script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'AW-774709547'); </script> 
	
		
                            		                                                <link href="/user/themes/deliver/css-compiled/nucleus.css" type="text/css" rel="stylesheet" />
<link href="/user/themes/deliver/css-compiled/template.css" type="text/css" rel="stylesheet" />
<link href="/user/themes/deliver/css/custom.css" type="text/css" rel="stylesheet" />
<link href="/user/themes/deliver/css/toc.css" type="text/css" rel="stylesheet" />
<link href="/user/themes/deliver/css/font-awesome.min.css" type="text/css" rel="stylesheet" />
<link href="/user/plugins/facebook/css/facebook.css" type="text/css" rel="stylesheet" />
<link href="/user/plugins/facebook/assets/unitegallery/css/unite-gallery.css" type="text/css" rel="stylesheet" />
<link href="/user/plugins/facebook/assets/unitegallery/themes/default/ug-theme-default.css" type="text/css" rel="stylesheet" />
<link href="/user/plugins/markdown-notices/assets/notices.css" type="text/css" rel="stylesheet" />
<link href="/user/plugins/breadcrumbs/css/breadcrumbs.css" type="text/css" rel="stylesheet" />
<link href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.0.3/cookieconsent.min.css" type="text/css" rel="stylesheet" />
<link href="/user/plugins/events/assets/events.css" type="text/css" rel="stylesheet" />
<link href="/user/plugins/form/assets/form-styles.css" type="text/css" rel="stylesheet" />
<link href="/user/plugins/mathjax/assets/css/mathjax.css" type="text/css" rel="stylesheet" />
<link href="/user/plugins/simplesearch/css/simplesearch.css" type="text/css" rel="stylesheet" />
<link href="/user/plugins/highlight/css/zenburn.css" type="text/css" rel="stylesheet" />
<link href="/user/plugins/login/css/login.css" type="text/css" rel="stylesheet" />
<link href="/user/themes/deliver/css/slidebars.min.css" type="text/css" rel="stylesheet" />
<link href="/user/themes/deliver/css/slideme.css" type="text/css" rel="stylesheet" />
<link href="/user/plugins/socialbuttons/vendor/rrssb/css/rrssb.css" type="text/css" rel="stylesheet" />


                                                            <script src="/system/assets/jquery/jquery-2.x.min.js" type="text/javascript" ></script>
<script src="/user/themes/deliver/js/modernizr.custom.71422.js" type="text/javascript" ></script>
<script src="/user/plugins/facebook/assets/unitegallery/js/unitegallery.min.js" type="text/javascript" ></script>
<script src="/user/plugins/facebook/assets/unitegallery/themes/default/ug-theme-default.js" type="text/javascript" ></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.0.3/cookieconsent.min.js" type="text/javascript" ></script>
<script src="/user/plugins/events/assets/events.js" type="text/javascript" ></script>
<script src="/user/plugins/mathjax/assets/js/mathjax.js" type="text/javascript" ></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript" ></script>
<script src="/user/plugins/highlight/js/highlight.pack.js" type="text/javascript" ></script>
<script src="/user/themes/deliver/js/deliver.js" type="text/javascript" ></script>
<script src="/user/themes/deliver/js/slidebars.min.js" type="text/javascript" ></script>
<script src="/user/themes/deliver/js/jquery.slideme2.js" type="text/javascript" ></script>
<script src="/user/plugins/socialbuttons/vendor/rrssb/js/rrssb.min.js" type="text/javascript" ></script>

<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
"palette": {
    "popup": {
        "background": "#4d4d4d",
        "text": "#fff"
    },
    "button": {
        "background": "#f1d600",
        "text": "#000",
        "border": "#f1d600"
    }
},
"position": "bottom",
"theme": "block",
"content": {
    "message": "This website uses cookies to ensure you get the best experience on our website.",
    "dismiss": "Got it!",
    "link": "Learn more",
    "href": "https://cookiesandyou.com"
}
})});
hljs.initHighlightingOnLoad();

</script>


</head>
<body id="top" class="header-lite fullwidth blogstyling">
    <div id="sb-site">
                <header id="header">
                <div class="logo">
                    <h3><a href="https://iaml.it"><img src="/user/pages/images/IAML_logo_viola.png" /></a></h3>
                                            <ul class="social-icons">
            <li>
            <a href="https://twitter.com/iaml_it">
                <i class="fa fa-twitter"></i>            </a>
        </li>
            <li>
            <a href="https://www.linkedin.com/company/iaml/">
                <i class="fa fa-linkedin"></i>            </a>
        </li>
            <li>
            <a href="https://www.facebook.com/machinelearningitalia/">
                <i class="fa fa-facebook"></i>            </a>
        </li>
            <li>
            <a href="blog.rss">
                <i class="fa fa-rss"></i>            </a>
        </li>
    </ul>  
                                    </div>
                <div id="navbar">
                                                            
<ul class="navigation">
                                                        <li class="">
                    <a href="/">
                                                Home
                    </a>
                </li>
                                                                <li class="">
                    <a href="/activities">
                                                Activities
                    </a>
                </li>
                                                                <li class="">
                    <a href="/supporters">
                                                Supporters
                    </a>
                </li>
                                                                <li class="">
                    <a href="/member">
                                                Become a member
                    </a>
                </li>
                                                                <li class="active">
                    <a href="/blog">
                                                Blog
                    </a>
                </li>
                                                                <li class="">
                    <a href="/governance">
                                                Governance
                    </a>
                </li>
                                                                                                                                </ul>                                                   <form class="search-box">
    <input type="search" placeholder="Search..." value="" data-search-input="/search/query" />
    <script>
    jQuery(document).ready(function($){
        var input = $('[data-search-input]');

        input.on('keypress', function(event) {
            if (event.which == 13 && input.val().length > 3) {
                event.preventDefault();
                window.location.href = input.data('search-input') + ':' + input.val();
            }
        });
    });
    </script>
    <i class="fa fa-search"></i>
</form>                    <span class="panel-activation sb-toggle-left navbar-left menu-btn fa fa-bars"></span>
                </div>
        </header>
        
        
                <section id="body" class="">
                            
				<div class="flush-top blog-header blog-header-image" style="background: #B4B093 url(/user/pages/05.blog/blue_header.jpg) no-repeat right;">
            <h1>Reinforcement Learning 1 - The Basics</h1>
        </div>
            
        
<div id="breadcrumbs" itemscope itemtype="http://data-vocabulary.org/Breadcrumb">
                                            <a href="/" itemprop="url"><span itemprop="title">Home</span></a>
                        <i class="fa fa-angle-right"></i>
                                                <a href="/blog" itemprop="url"><span itemprop="title">Blog</span></a>
                        <i class="fa fa-angle-right"></i>
                                                <span itemprop="title">Reinforcement Learning 1 - The Basics</span>
                        </div>
		
		<div class="blog-content-item g-grid pure-g-r">
			<div id="item" class="g-block pure-u-2-3">
			    <div class="list-item">

    <div class="list-blog-header">
                    <img src="/images/0/1/7/e/a/017eae0996dd44a844f8f19773347c3fd9f14267-markovchain.png" />
        
                    <h4><a href="/blog/reinforcement-learning-1">Reinforcement Learning 1 - The Basics</a></h4>
        
        <span class="list-blog-date">
            <i class="fa fa-calendar"></i>
            11, Mar
        </span>
                <span class="list-blog-author">
            <i class="fa fa-user"></i>
            Daniele Paliotta
        </span>
               
    </div>

	<div>
	<br />
	<!-- AddToAny BEGIN -->
<div class="a2a_kit a2a_kit_size_32 a2a_default_style">
<a class="a2a_dd" href="https://www.addtoany.com/share"></a>
<a class="a2a_button_facebook"></a>
<a class="a2a_button_twitter"></a>
<a class="a2a_button_linkedin"></a>
<a class="a2a_button_google_plus"></a>
<a class="a2a_button_email"></a>
</div>
<script async src="https://static.addtoany.com/menu/page.js"></script>
<!-- AddToAny END -->
</div>
	
    <div class="list-blog-padding">

            <p><p><em>Reinforcement learning</em> is an area of machine learning concerned with the behaviour of an agent in an environment, whose goal is to interact with the environment in order to maximize some type of reward. This general idea can be applied to solve a wide range of tasks, from winning at chess to <a href="https://en.wikipedia.org/wiki/AlphaZero">beating the world champion of Go</a>, from teaching a robot how to move to <a href="http://advances.sciencemag.org/content/4/7/eaap7885">designing new drugs</a>. In this article, we will cover part of the theoretical foundations of reinforcement learning, starting with Markov Decision Processes (MDPs) and value functions. These will give us a foundation for treating reinforcement learning problems in general.</p>
<nav class="table-of-contents minitoc" role="navigation">
                <span class="toctitle">Overview:</span>
      
                                                                
  <ul>
      
        
        
              <li><a href="#what-is-a-markov-decision..." class="toclink" title="What is a Markov Decision Process?">What is a Markov Decision Process?</a></li>
      
        
        
              <li><a href="#from-md-ps-to-markov-reward..." class="toclink" title="From MDPs to Markov Reward Processes">From MDPs to Markov Reward Processes</a></li>
      
                      <li><ul>
          
        
              <li><a href="#why-do-we-need-to-discount" class="toclink" title="Why do we need to discount?">Why do we need to discount?</a></li>
      
                      </ul></li>
          
        
              <li><a href="#the-value-function" class="toclink" title="The Value Function">The Value Function</a></li>
      
        
        
              <li><a href="#finally-a-complete-mdp" class="toclink" title="Finally, a complete MDP">Finally, a complete MDP</a></li>
      
        
        
              <li><a href="#optimal-value-function" class="toclink" title="Optimal Value Function">Optimal Value Function</a></li>
      
        
        
              <li><a href="#further-readings-and-resources" class="toclink" title="Further readings and resources">Further readings and resources</a></li>
      
        
        
              <li><a href="#about-the-author" class="toclink" title="About the author">About the author</a></li>
      
    
  </ul>
</nav>


<h2 id="what-is-a-markov-decision..." class="headeranchor"><a class="headeranchor-link headeranchor-link--left headeranchor-visible--hover" aria-hidden="true" href="#what-is-a-markov-decision..." title="Permanent link: What is a Markov Decision Process?" data-icon="#">What is a Markov Decision Process?</a></h2>
<p>To speak concretely about Reinforcement Learning, we fist need to define Markov Decision Processes (MDPs). <a href="https://en.wikipedia.org/wiki/Markov_decision_process">Wikipedia</a> states that MDPs <em>provide a mathematical framework for modeling decision making in situations where outcomes are partly random and partly under the control of a decision maker</em>.</p>
<p>We will see what this means in detail later on. The important thing to understand is that MDPs formally describe an environment for RL. The agent will interact with such environment, guided by the rewards it gets along the way.</p>
<figure role="group">
        <img src="https://iaml.it/blog/reinforcement-learning-1/images/1_au5pJs3dt5NEBORVmwpPRA.png" alt="Rl Environment">
        </figure>
<figcaption>Source: Sutton, R.S. and Barto, A.G., 2011. Reinforcement learning: An introduction.</figcaption>
<p>The basic entities of MDPs are its <em>states</em>. A state in an MDP is called a <em>Markov</em> state, meaning that a particular state <strong>captures all relevant information from history</strong>. Once we know a state, history can be thrown away.</p>
<p class="mathjax mathjax--block">\[
\begin{align*}
P[S_{t+1} \mid S_t] = P[S_{t+1} \mid S_1,S_2,...,S_t]
\end{align*}\]</p>
<p>In addition to a set of states, we also need to define the <em>state transition probabilities</em>.
A state transition probability defines the probability of going from state <em>s</em> to state <em>s'</em>.</p>
<p class="mathjax mathjax--block">\[
\begin{align*}
  \textit{P}_{ss'} = P[S_{t+1} = s' \mid S_t = s]
\end{align*}\]</p>
<p>As a more compact way of representing such probabilities, we define the <em>state transition matrix P</em>.</p>
<p class="mathjax mathjax--block">\[
\begin{align*}
  \textit{P} =  
  \begin{bmatrix}
    P_{11}  & \dots & P_{1n} \\\
    \vdots \\\
    P_{n1}  &  \dots & P_{nn}
  \end{bmatrix}
\end{align*}\]</p>
<p>This matrix defines the transition probability for each possible pair of states. Given the elements we just defined, we can now define a generic <em>Markov process</em>, also called <em>Markov Chain</em>:</p>
<p class="mathjax mathjax--block">\[
\begin{align*}
  \text{A Markov process is a tuple } \langle S,P \rangle \text{  in which: }
\end{align*}\]</p>
<ul>
<li><span class="mathjax mathjax--inline">$S$</span> is a set of states.</li>
<li><span class="mathjax mathjax--inline">$P$</span> is  a state transition probability matrix.</li>
</ul>
<figure role="group">
        <img src="https://iaml.it/blog/reinforcement-learning-1/images/markovchain.png" alt="markov-chain">
        </figure>
<figcaption>Source: Sutton, R.S. and Barto, A.G., 2011. Reinforcement learning: An introduction.</figcaption>
<h2 id="from-md-ps-to-markov-reward..." class="headeranchor"><a class="headeranchor-link headeranchor-link--left headeranchor-visible--hover" aria-hidden="true" href="#from-md-ps-to-markov-reward..." title="Permanent link: From MDPs to Markov Reward Processes" data-icon="#">From MDPs to Markov Reward Processes</a></h2>
<p>If we add only two more ingredients to out Markov Process, we get a <em>Markov Reward Process</em>.</p>
<p>As you can guess, one of these elements is a <strong>Reward Function</strong>. A Reward Function represents a very simple thing: for each state in our process, it tells us the expected value of the reward in that state.</p>
<p class="mathjax mathjax--block">\[
\begin{align*}
  R_s = E[R_{t+1} \mid S_t = s]
\end{align*}\]</p>
<p>The second elements is more subtle: it's the discount factor.</p>
<p class="mathjax mathjax--block">\[
\begin{align*}
  \gamma \in [0,1]
\end{align*}\]</p>
<p>The discount factor, as you will see, is used to decrease the value of rewards in the future. We are now ready to define our <em>return</em> <span class="mathjax mathjax--inline">$G_t$</span>.</p>
<p class="mathjax mathjax--block">\[
\begin{align*}
  G_t = R_{t+1} + \gamma R_{t+1} + ... = \sum_{k=0}^{\infty} \gamma^k R_{t+1+k}
\end{align*}\]</p>
<p>As you can see, the return is nothing but the total discounted reward from time-step <em>t</em>.</p>
<h3 id="why-do-we-need-to-discount" class="headeranchor"><a class="headeranchor-link headeranchor-link--left headeranchor-visible--hover" aria-hidden="true" href="#why-do-we-need-to-discount" title="Permanent link: Why do we need to discount?" data-icon="#">Why do we need to discount?</a></h3>
<p>Most Markov Reward Process are discounted and there are several reasons to this. Mainly, discounting rewards allows us to represent uncertainty about the future, but it also helps us model human behaviour better, since it has been shown that humans/animals have a preference for immediate rewards.</p>
<p>Also, the math is easier if we use discount factors, and we are able to avoid infinite returns in cyclic processes.</p>
<h2 id="the-value-function" class="headeranchor"><a class="headeranchor-link headeranchor-link--left headeranchor-visible--hover" aria-hidden="true" href="#the-value-function" title="Permanent link: The Value Function" data-icon="#">The Value Function</a></h2>
<p>We are now ready to define one of the most important functions in Reinforcement Learning: the <strong>value function</strong>, also called <strong>state value function</strong>.</p>
<p>The <em>value function</em> of a MRP is the expected return starting from state S.</p>
<p class="mathjax mathjax--block">\[
\begin{align*}
  v(s) = E[G_t \mid S_t = s]
\end{align*}\]</p>
<p>This function can be decomposed into two parts:</p>
<ul>
<li>immediate reward <span class="mathjax mathjax--inline">$R_{t+1}$</span></li>
<li>discounted value of successor state <span class="mathjax mathjax--inline">$\gamma v(S_{t+1})$</span>, as follows:</li>
</ul>
<p class="mathjax mathjax--block">\[
\begin{align}
  v(s) & = E[G_t \mid S_t = s] = E[R_{t+1} + \gamma R_{t+2} + \gamma^2 R_{t+3} + \ldots \mid S_t = s] \\
  & = E[R_{t+1} + \gamma (R_{t+2} + \gamma R_{t+3} +  \ldots) \mid S_t = s]   \\
  & = E[R_{t+1} + \gamma G_{t+1} \mid S_t = s]  \\
  & = E[R_{t+1} + \gamma v(S_{t+1}) \mid S_t = s]   \\
 \end{align}\]</p>
<p>This formula for the value function takes the name of <strong>Bellman equation</strong>. It is of fundamental importance because it allows us to have a recursive representation of the value function.
This property is important in practice, when we need to implement ways of computing/evaluating/maximizing this function.</p>
<p>The Bellman equation can also be expressed using matrices.</p>
<p class="mathjax mathjax--block">\[
\begin{align*}
  v = R + \gamma P v
\end{align*}\]</p>
<p>where <span class="mathjax mathjax--inline">$v$</span> is a column vector with one entry per state.</p>
<p class="mathjax mathjax--block">\[
\begin{align*}
  \begin{bmatrix}
    v(1) \\\
    \vdots \\\
    v(n)  
  \end{bmatrix}
  =
  \begin{bmatrix}
    R_1 \\\
    \vdots \\\
    R_n  
  \end{bmatrix}
  +
  \gamma
  \begin{bmatrix}
    P_{11}  & \dots & P_{1n} \\\
    \vdots \\\
    P_{n1}  &  \dots & P_{nn}
  \end{bmatrix}
  \begin{bmatrix}
    v(1) \\\
    \vdots \\\
    v(n)  
  \end{bmatrix}
\end{align*}\]</p>
<p>The Bellman Equation is linear, which means that we can solve it directly. However, the computational complexity is <span class="mathjax mathjax--inline">$\mathcal{O}(n^3)$</span>, which makes it unfeasible to compute for big MRPs with many states.</p>
<p>Therefore, in practice, iterative methods are used, such as Dynamic Programming, Monte-Carlo evaluation, and Temporal Difference. We will see these methods in detail in future posts of these series.</p>
<h2 id="finally-a-complete-mdp" class="headeranchor"><a class="headeranchor-link headeranchor-link--left headeranchor-visible--hover" aria-hidden="true" href="#finally-a-complete-mdp" title="Permanent link: Finally, a complete MDP" data-icon="#">Finally, a complete MDP</a></h2>
<p>We are now ready to add our last ingredient to have a complete MDP: a set of <strong>Actions</strong> <em>A</em>.</p>
<p>Le't sum it up: a <em>Markov Decision Process</em> is a tuple <span class="mathjax mathjax--inline">$\langle S,A,P,R,\gamma \rangle$</span></p>
<ul>
<li><span class="mathjax mathjax--inline">$S$</span> is a finite set of states</li>
<li><span class="mathjax mathjax--inline">$A$</span> is a finite set of actions</li>
<li><span class="mathjax mathjax--inline">$P$</span> is a state transition probability matrix
<span class="mathjax mathjax--inline">$\textit{P}_{ss'}^a = P[S_{t+1} = s' \mid S_t = s, A_t = a]$</span></li>
<li><span class="mathjax mathjax--inline">$R$</span> is a reward function <span class="mathjax mathjax--inline">$ R_s^a = E[R_{t+1} \mid S_t = s, A_t = a]$</span></li>
<li><span class="mathjax mathjax--inline">$\gamma$</span> is a discount factor <span class="mathjax mathjax--inline">$\gamma \in [0,1]$</span></li>
</ul>
<p>Now that we have our MDP, we can define the behaviour of an <em>agent</em> in this environment. We define the agent's behaviour with a <strong>policy</strong> <span class="mathjax mathjax--inline">$\pi$</span>, which is simply a <em>distribution over actions given states</em>. It basically maps states to the probabilities of our agent taking each possible action from that state. </p>
<p>Simple, right?</p>
<p class="mathjax mathjax--block">\[
\begin{align*}
  \pi (a \mid s) = P[A_t = a \mid S_t = s]
\end{align*}\]</p>
<p>We can now rewrite our value function, when we follow policy <span class="mathjax mathjax--inline">$\pi$</span>:</p>
<p class="mathjax mathjax--block">\[
\begin{align*}
  v_{\pi}(s) = E_{\pi}[G_t \mid S_t = s]
\end{align*}\]</p>
<p>This equation represents the expected return starting from state <span class="mathjax mathjax--inline">$s$</span>, and following policy <span class="mathjax mathjax--inline">$\pi$</span>.</p>
<p>Another important function in RL, called <em>action-value</em> function, expresses the expected value of first taking a certain action, and then following a certain policy.</p>
<p class="mathjax mathjax--block">\[
\begin{align*}
  q_{\pi}(s,a) = E_{\pi}[G_t \mid S_t = s, A_t = a]
\end{align*}\]</p>
<p>Again, we can rewrite our value function in the Bellman form:</p>
<p class="mathjax mathjax--block">\[
\begin{align*}
  v_{\pi}(s)  
  = E_{\pi}[R_{t+1} + \gamma v_{\pi}(S_{t+1}) \mid S_t = s]  
\end{align*}\]</p>
<p>And we can write the <em>action-value</em> function in a similar fashion:</p>
<p class="mathjax mathjax--block">\[
\begin{align*}
  q_{\pi}(s,a)  
  = E_{\pi}[R_{t+1} + \gamma q_{\pi}(S_{t+1}, A_{t+1}) \mid S_t = s, A_t = a]  
\end{align*}\]</p>
<h2 id="optimal-value-function" class="headeranchor"><a class="headeranchor-link headeranchor-link--left headeranchor-visible--hover" aria-hidden="true" href="#optimal-value-function" title="Permanent link: Optimal Value Function" data-icon="#">Optimal Value Function</a></h2>
<p>The optimal <em>state-value</em> function <span class="mathjax mathjax--inline">$v*(s)$</span> is the maximum value function over all policies.</p>
<p class="mathjax mathjax--block">\[
\begin{align*}
  v*(s) = \max_{\pi} v_{\pi}(s)
\end{align*}\]</p>
<p>Similarly, the optimal <em>action-value</em> function is the maximum action-value function over all policies.</p>
<p class="mathjax mathjax--block">\[
\begin{align*}
  q*(s,a) = \max_{\pi} q_{\pi}(s,a)
\end{align*}\]</p>
<p>We say that an MDP is <strong>solved</strong> when we find the optimal value function.</p>
<hr />
<h2 id="further-readings-and-resources" class="headeranchor"><a class="headeranchor-link headeranchor-link--left headeranchor-visible--hover" aria-hidden="true" href="#further-readings-and-resources" title="Permanent link: Further readings and resources" data-icon="#">Further readings and resources</a></h2>
<ul>
<li><a href="https://www.youtube.com/watch?v=lfHX2hHRMVQ&list=PLzuuYNsE1EZAXYR4FJ75jcJseBmo4KQ9-&ab_channel=DeepMind">David Silver lecture on MDPs</a></li>
<li><a href="http://www.incompleteideas.net/book/the-book-2nd.html">Sutton and Barto book on Reinforcement Learning</a></li>
</ul>
<hr />
<h2 id="about-the-author" class="headeranchor"><a class="headeranchor-link headeranchor-link--left headeranchor-visible--hover" aria-hidden="true" href="#about-the-author" title="Permanent link: About the author" data-icon="#">About the author</a></h2>
<p>Daniele is a computer engineering graduate student in Turin, focusing on data science and machine learning. He graduated from his bachelor with a thesis on generative models. He also organises the Machine Learning study group in Turin.
Previously, he worked as a software engineer, and presented his projects at Tel Aviv University and Google Tel Aviv. He was also selected to participate in the first edition of <a href="https://cyberchallenge.it/">CyberChallenge.it</a>.</p>
<hr />
<p>If you liked our article, remember that subscribing to the <a href="/member">Italian Association for Machine Learning</a> is free! You can follow us daily on <a href="https://www.facebook.com/machinelearningitalia/">Facebook</a>, <a href="https://www.linkedin.com/company/iaml/">LinkedIn</a>, and <a href="https://twitter.com/iaml_it">Twitter</a>.</p></p>
            
    
        <p class="prev-next">
                            <a class="button" href="/blog/novita-tensorflow-2"><i class="fa fa-chevron-left"></i> Previous Post</a>
            
                            <a class="button" href="/blog/differenziazione-automatica-parte-2">Next Post <i class="fa fa-chevron-right"></i></a>
                    </p>
    
    </div>
</div>
			</div>
			<div id="sidebar" class="g-block size-1-3 pure-u-1-3">
				<div class="sidebar-content">
    <h4>Search the blog</h4>
    <input type="text" placeholder="Search..." value="" data-searchsidebar-input="/search/query" />
<script>
jQuery(document).ready(function($){
    var input = $('[data-searchsidebar-input]');

    input.on('keypress', function(event) {
        if (event.which == 13 && input.val().length > 3) {
            event.preventDefault();
            window.location.href = input.data('searchsidebar-input') + ':' + input.val();
        }
    });
});
</script>
</div>
<!--
<div class="sidebar-content">
	<h4>Some Text Widget</h4>
	<p>Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna.</p>
</div>
!-->
<div class="sidebar-content">
    <h4>Categories</h4>
    

<ul class="archives">
        <li>
        <a href="/blog/category:Tutorials">Tutorials </a> (16)
    </li>
        <li>
        <a href="/blog/category:Discussions">Discussions </a> (12)
    </li>
        <li>
        <a href="/blog/category:Announcements">Announcements </a> (4)
    </li>
        <li>
        <a href="/blog/category:Tutorials%20%28English%29">Tutorials (English) </a> (4)
    </li>
        <li>
        <a href="/blog/category:Articles%27%20summaries">Articles' summaries </a> (3)
    </li>
        <li>
        <a href="/blog/category:Discussions%20%28English%29">Discussions (English) </a> (2)
    </li>
        <li>
        <a href="/blog/category:Focus-on">Focus-on </a> (1)
    </li>
        <li>
        <a href="/blog/category:Reviews">Reviews </a> (1)
    </li>
        <li>
        <a href="/blog/category:Discussion">Discussion </a> (1)
    </li>
    </ul>
</div>
<div class="sidebar-content">
    <h4>Archives</h4>
	<ul class="archives">
    <li>
    	<a href="/blog/archives_month:apr_2020">
        <span class="archive_date">April 2020</span>
                <span>(1)</span>
                </a>
    </li>
</ul>
</div>
<div class="sidebar-content">
    <h4>Popular Tags</h4>
    

<ul class="archives">
        <li>
        <a href="/blog/tag:deep%20learning">deep learning </a> (11)
    </li>
        <li>
        <a href="/blog/tag:pytorch">pytorch </a> (9)
    </li>
        <li>
        <a href="/blog/tag:reti%20neurali">reti neurali </a> (5)
    </li>
        <li>
        <a href="/blog/tag:google">google </a> (4)
    </li>
        <li>
        <a href="/blog/tag:jit">jit </a> (4)
    </li>
        <li>
        <a href="/blog/tag:tensorflow">tensorflow </a> (4)
    </li>
        <li>
        <a href="/blog/tag:ottimizzazione">ottimizzazione </a> (4)
    </li>
        <li>
        <a href="/blog/tag:rete%20neurale">rete neurale </a> (3)
    </li>
        <li>
        <a href="/blog/tag:time%20series">time series </a> (3)
    </li>
        <li>
        <a href="/blog/tag:keras">keras </a> (3)
    </li>
        <li>
        <a href="/blog/tag:reti%20convolutive">reti convolutive </a> (3)
    </li>
        <li>
        <a href="/blog/tag:pipeline">pipeline </a> (2)
    </li>
        <li>
        <a href="/blog/tag:sklearn">sklearn </a> (2)
    </li>
        <li>
        <a href="/blog/tag:autodiff">autodiff </a> (2)
    </li>
        <li>
        <a href="/blog/tag:automatic%20differentation">automatic differentation </a> (2)
    </li>
        <li>
        <a href="/blog/tag:reverse-mode">reverse-mode </a> (2)
    </li>
        <li>
        <a href="/blog/tag:derivate">derivate </a> (2)
    </li>
        <li>
        <a href="/blog/tag:differenziazione">differenziazione </a> (2)
    </li>
        <li>
        <a href="/blog/tag:model%20selection">model selection </a> (2)
    </li>
        <li>
        <a href="/blog/tag:cross%20validation">cross validation </a> (2)
    </li>
        <li>
        <a href="/blog/tag:c%2B%2B">c++ </a> (2)
    </li>
        <li>
        <a href="/blog/tag:numpy">numpy </a> (2)
    </li>
        <li>
        <a href="/blog/tag:vmap">vmap </a> (2)
    </li>
        <li>
        <a href="/blog/tag:caffe">caffe </a> (2)
    </li>
        <li>
        <a href="/blog/tag:compiler">compiler </a> (2)
    </li>
        <li>
        <a href="/blog/tag:jax">jax </a> (2)
    </li>
        <li>
        <a href="/blog/tag:codemotion">codemotion </a> (1)
    </li>
        <li>
        <a href="/blog/tag:bias">bias </a> (1)
    </li>
        <li>
        <a href="/blog/tag:discrimination">discrimination </a> (1)
    </li>
        <li>
        <a href="/blog/tag:fairness">fairness </a> (1)
    </li>
        <li>
        <a href="/blog/tag:iaml">iaml </a> (1)
    </li>
        <li>
        <a href="/blog/tag:database">database </a> (1)
    </li>
        <li>
        <a href="/blog/tag:iperparametri">iperparametri </a> (1)
    </li>
        <li>
        <a href="/blog/tag:autograph">autograph </a> (1)
    </li>
        <li>
        <a href="/blog/tag:head">head </a> (1)
    </li>
        <li>
        <a href="/blog/tag:multi-task">multi-task </a> (1)
    </li>
        <li>
        <a href="/blog/tag:learning">learning </a> (1)
    </li>
        <li>
        <a href="/blog/tag:novit%C3%A0">novità </a> (1)
    </li>
        <li>
        <a href="/blog/tag:dev%20summit">dev summit </a> (1)
    </li>
        <li>
        <a href="/blog/tag:custom%20estimator">custom estimator </a> (1)
    </li>
        <li>
        <a href="/blog/tag:hyperopt">hyperopt </a> (1)
    </li>
        <li>
        <a href="/blog/tag:goodfellow">goodfellow </a> (1)
    </li>
        <li>
        <a href="/blog/tag:nlp">nlp </a> (1)
    </li>
        <li>
        <a href="/blog/tag:dati%20mancanti">dati mancanti </a> (1)
    </li>
        <li>
        <a href="/blog/tag:transformer">transformer </a> (1)
    </li>
        <li>
        <a href="/blog/tag:attenzione">attenzione </a> (1)
    </li>
        <li>
        <a href="/blog/tag:robocop">robocop </a> (1)
    </li>
        <li>
        <a href="/blog/tag:yolo">yolo </a> (1)
    </li>
        <li>
        <a href="/blog/tag:object%20detection">object detection </a> (1)
    </li>
        <li>
        <a href="/blog/tag:bayes">bayes </a> (1)
    </li>
        <li>
        <a href="/blog/tag:autoencoders">autoencoders </a> (1)
    </li>
        <li>
        <a href="/blog/tag:variational">variational </a> (1)
    </li>
        <li>
        <a href="/blog/tag:eager">eager </a> (1)
    </li>
        <li>
        <a href="/blog/tag:imputazione">imputazione </a> (1)
    </li>
        <li>
        <a href="/blog/tag:CIFAR">CIFAR </a> (1)
    </li>
        <li>
        <a href="/blog/tag:word%20embedding">word embedding </a> (1)
    </li>
        <li>
        <a href="/blog/tag:MNIST">MNIST </a> (1)
    </li>
        <li>
        <a href="/blog/tag:immagini">immagini </a> (1)
    </li>
        <li>
        <a href="/blog/tag:classificazione">classificazione </a> (1)
    </li>
        <li>
        <a href="/blog/tag:kpi">kpi </a> (1)
    </li>
        <li>
        <a href="/blog/tag:reprogramming">reprogramming </a> (1)
    </li>
        <li>
        <a href="/blog/tag:adversarial">adversarial </a> (1)
    </li>
        <li>
        <a href="/blog/tag:browser">browser </a> (1)
    </li>
        <li>
        <a href="/blog/tag:javascript">javascript </a> (1)
    </li>
        <li>
        <a href="/blog/tag:reti%20ricorsive">reti ricorsive </a> (1)
    </li>
        <li>
        <a href="/blog/tag:reti%20ricorrenti">reti ricorrenti </a> (1)
    </li>
        <li>
        <a href="/blog/tag:ftth">ftth </a> (1)
    </li>
        <li>
        <a href="/blog/tag:adversarial%20example">adversarial example </a> (1)
    </li>
        <li>
        <a href="/blog/tag:management">management </a> (1)
    </li>
        <li>
        <a href="/blog/tag:robotica">robotica </a> (1)
    </li>
        <li>
        <a href="/blog/tag:ocr">ocr </a> (1)
    </li>
        <li>
        <a href="/blog/tag:focus">focus </a> (1)
    </li>
        <li>
        <a href="/blog/tag:iphone">iphone </a> (1)
    </li>
        <li>
        <a href="/blog/tag:python">python </a> (1)
    </li>
        <li>
        <a href="/blog/tag:face%20id">face id </a> (1)
    </li>
        <li>
        <a href="/blog/tag:momento">momento </a> (1)
    </li>
        <li>
        <a href="/blog/tag:adam">adam </a> (1)
    </li>
        <li>
        <a href="/blog/tag:neuroscienza">neuroscienza </a> (1)
    </li>
        <li>
        <a href="/blog/tag:onde%20cerebrali">onde cerebrali </a> (1)
    </li>
        <li>
        <a href="/blog/tag:torchvision">torchvision </a> (1)
    </li>
        <li>
        <a href="/blog/tag:latin">latin </a> (1)
    </li>
        <li>
        <a href="/blog/tag:pretrained">pretrained </a> (1)
    </li>
        <li>
        <a href="/blog/tag:rete%20convolutiva">rete convolutiva </a> (1)
    </li>
        <li>
        <a href="/blog/tag:autograd">autograd </a> (1)
    </li>
        <li>
        <a href="/blog/tag:swish">swish </a> (1)
    </li>
        <li>
        <a href="/blog/tag:attivazione">attivazione </a> (1)
    </li>
        <li>
        <a href="/blog/tag:checkpoint">checkpoint </a> (1)
    </li>
        <li>
        <a href="/blog/tag:tensori">tensori </a> (1)
    </li>
        <li>
        <a href="/blog/tag:variabili">variabili </a> (1)
    </li>
        <li>
        <a href="/blog/tag:lineare">lineare </a> (1)
    </li>
        <li>
        <a href="/blog/tag:regressione">regressione </a> (1)
    </li>
        <li>
        <a href="/blog/tag:convolutional%20networks">convolutional networks </a> (1)
    </li>
        <li>
        <a href="/blog/tag:Vatican">Vatican </a> (1)
    </li>
        <li>
        <a href="/blog/tag:project">project </a> (1)
    </li>
        <li>
        <a href="/blog/tag:kernel">kernel </a> (1)
    </li>
        <li>
        <a href="/blog/tag:ICLR">ICLR </a> (1)
    </li>
        <li>
        <a href="/blog/tag:ipotesi">ipotesi </a> (1)
    </li>
        <li>
        <a href="/blog/tag:sparsit%C3%A0">sparsità </a> (1)
    </li>
        <li>
        <a href="/blog/tag:funzionale">funzionale </a> (1)
    </li>
        <li>
        <a href="/blog/tag:functional">functional </a> (1)
    </li>
        <li>
        <a href="/blog/tag:adversarial%20attack">adversarial attack </a> (1)
    </li>
        <li>
        <a href="/blog/tag:kmeans">kmeans </a> (1)
    </li>
        <li>
        <a href="/blog/tag:analysis">analysis </a> (1)
    </li>
        <li>
        <a href="/blog/tag:clustering">clustering </a> (1)
    </li>
        <li>
        <a href="/blog/tag:Google">Google </a> (1)
    </li>
        <li>
        <a href="/blog/tag:regression">regression </a> (1)
    </li>
        <li>
        <a href="/blog/tag:JAX">JAX </a> (1)
    </li>
        <li>
        <a href="/blog/tag:gaussian%20process">gaussian process </a> (1)
    </li>
        <li>
        <a href="/blog/tag:ensemble">ensemble </a> (1)
    </li>
        <li>
        <a href="/blog/tag:boosting">boosting </a> (1)
    </li>
        <li>
        <a href="/blog/tag:gradient">gradient </a> (1)
    </li>
        <li>
        <a href="/blog/tag:semi-supervised%20learning">semi-supervised learning </a> (1)
    </li>
        <li>
        <a href="/blog/tag:document%20classification">document classification </a> (1)
    </li>
        <li>
        <a href="/blog/tag:graphs">graphs </a> (1)
    </li>
        <li>
        <a href="/blog/tag:variables">variables </a> (1)
    </li>
        <li>
        <a href="/blog/tag:linear">linear </a> (1)
    </li>
        <li>
        <a href="/blog/tag:k-NN">k-NN </a> (1)
    </li>
    </ul>
</div>
<div class="sidebar-content syndicate">
    <h4>Syndicate</h4>
    <a class="button" href="/blog.atom"><i class="fa fa-rss-square"></i> Atom 1.0</a>
    <a class="button" href="/blog.rss"><i class="fa fa-rss-square"></i> RSS</a>
</div>
			</div>
		</div>
	
                        <div class="modular-row footer ">
    <div class="footer-items">
        <div class="footer-module large">
		<h4>About</h4>
                            <p>Italian Association for Machine Learning (C.F. 97949550582)</p>
            			<p>Write us: info@iaml.it</p>
        </div>
        <div class="footer-module"><h4>Address</h4>
            <p>
                                    <span><strong>Operational office</strong></span>
                                    <span>IAML c/o Pi Campus, via Indonesia 23, 00144 Rome</span>
                                    <span><strong>Legal office</strong></span>
                                    <span>Via Cassia 964, 00189, Rome</span>
                            </p>
        </div>
        <div class="footer-module"><h4>Quick Links</h4>
         <ul class="quickmenu">
                            <li><i class="fa fa-chevron-right"></i><a href="https://iaml.it/home">Home</a></li>
                            <li><i class="fa fa-chevron-right"></i><a href="https://iaml.it/documents">Documents (Italian)</a></li>
                    </ul>
    </div>
   
</div>
<hr>
<div class="footer-modules">
    <div class="footer-copyright">
        Copyright 2018 IAML.IT. All Rights Reserved.
    </div>
    <div class="footer-menu">
    <ul class="othermenu">
           <li><a href="https://learn.getgrav.org/">Powered by Grav</a></li>
           <li><a href="https://github.com/getgrav/grav-theme-deliver">Theme (adapted) from Deliver</a></li>
        </ul>
    </div>
</div>
</div>                    </section>
        
    </div>
    <div class="sb-slidebar sb-left sb-width-thin">
        <div id="panel">
        
<ul class="navigation">
                                                        <li class="">
                    <a href="/">
                                                Home
                    </a>
                </li>
                                                                <li class="">
                    <a href="/activities">
                                                Activities
                    </a>
                </li>
                                                                <li class="">
                    <a href="/supporters">
                                                Supporters
                    </a>
                </li>
                                                                <li class="">
                    <a href="/member">
                                                Become a member
                    </a>
                </li>
                                                                <li class="active">
                    <a href="/blog">
                                                Blog
                    </a>
                </li>
                                                                <li class="">
                    <a href="/governance">
                                                Governance
                    </a>
                </li>
                                                                                                                                </ul>                   </div>
    </div>
        <script src="/user/plugins/simplesearch/js/simplesearch.js" type="text/javascript" ></script>

    <script>
    $(function () {
        $(document).ready(function() {
          $.slidebars({
            hideControlClasses: true,
            scrollLock: true
          });
        });
    });
    </script>
    </body>
</html>
