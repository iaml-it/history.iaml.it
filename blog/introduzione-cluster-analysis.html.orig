<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8" />
    <title>Introduzione alla Cluster Analysis | Italian Association for Machine Learning</title>
    <meta content="GravCMS"  />
<meta content="The Italian Association for Machine Learning (IAML) is a not-for-profit organization with the purpose of promoting knowledge of machine learning in all aspects of the Italian public life, from universities to enterprises and IT professionals."  />
<meta property="og:title" content="Introduzione alla Cluster Analysis | IAML.it"  />
<meta property="og:image" content="https://iaml.it/blog/introduzione-cluster-analysis/0OWDuTC.png"  />
<meta property="og:url" content="https://iaml.it/blog/introduzione-cluster-analysis/"  />
<meta property="og:description" content="In questo articolo vengono descritti i concetti di base della Cluster Analysis ed alcuni tra gli algoritmi più importanti e rappresentativi delle tecniche principali ad oggi utilizzate. Lo scopo è quello di far comprendere la finalità della suddivisione in cluster ed i meccanismi che si celano dietro la loro costruzione."  />
    <meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <link rel="icon" type="image/png" href="/user/themes/deliver/images/favicon.png" />

	<!-- Global site tag (gtag.js) - Google Ads: 774709547 --> <script async src="https://www.googletagmanager.com/gtag/js?id=AW-774709547"></script> <script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'AW-774709547'); </script> 
	
		
                            		                                                <link href="/user/themes/deliver/css-compiled/nucleus.css" type="text/css" rel="stylesheet" />
<link href="/user/themes/deliver/css-compiled/template.css" type="text/css" rel="stylesheet" />
<link href="/user/themes/deliver/css/custom.css" type="text/css" rel="stylesheet" />
<link href="/user/themes/deliver/css/toc.css" type="text/css" rel="stylesheet" />
<link href="/user/themes/deliver/css/font-awesome.min.css" type="text/css" rel="stylesheet" />
<link href="/user/plugins/facebook/css/facebook.css" type="text/css" rel="stylesheet" />
<link href="/user/plugins/facebook/assets/unitegallery/css/unite-gallery.css" type="text/css" rel="stylesheet" />
<link href="/user/plugins/facebook/assets/unitegallery/themes/default/ug-theme-default.css" type="text/css" rel="stylesheet" />
<link href="/user/plugins/markdown-notices/assets/notices.css" type="text/css" rel="stylesheet" />
<link href="/user/plugins/breadcrumbs/css/breadcrumbs.css" type="text/css" rel="stylesheet" />
<link href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.0.3/cookieconsent.min.css" type="text/css" rel="stylesheet" />
<link href="/user/plugins/events/assets/events.css" type="text/css" rel="stylesheet" />
<link href="/user/plugins/form/assets/form-styles.css" type="text/css" rel="stylesheet" />
<link href="/user/plugins/mathjax/assets/css/mathjax.css" type="text/css" rel="stylesheet" />
<link href="/user/plugins/simplesearch/css/simplesearch.css" type="text/css" rel="stylesheet" />
<link href="/user/plugins/highlight/css/zenburn.css" type="text/css" rel="stylesheet" />
<link href="/user/plugins/login/css/login.css" type="text/css" rel="stylesheet" />
<link href="/user/themes/deliver/css/slidebars.min.css" type="text/css" rel="stylesheet" />
<link href="/user/themes/deliver/css/slideme.css" type="text/css" rel="stylesheet" />
<link href="/user/plugins/socialbuttons/vendor/rrssb/css/rrssb.css" type="text/css" rel="stylesheet" />


                                                            <script src="/system/assets/jquery/jquery-2.x.min.js" type="text/javascript" ></script>
<script src="/user/themes/deliver/js/modernizr.custom.71422.js" type="text/javascript" ></script>
<script src="/user/plugins/facebook/assets/unitegallery/js/unitegallery.min.js" type="text/javascript" ></script>
<script src="/user/plugins/facebook/assets/unitegallery/themes/default/ug-theme-default.js" type="text/javascript" ></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.0.3/cookieconsent.min.js" type="text/javascript" ></script>
<script src="/user/plugins/events/assets/events.js" type="text/javascript" ></script>
<script src="/user/plugins/mathjax/assets/js/mathjax.js" type="text/javascript" ></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript" ></script>
<script src="/user/plugins/highlight/js/highlight.pack.js" type="text/javascript" ></script>
<script src="/user/themes/deliver/js/deliver.js" type="text/javascript" ></script>
<script src="/user/themes/deliver/js/slidebars.min.js" type="text/javascript" ></script>
<script src="/user/themes/deliver/js/jquery.slideme2.js" type="text/javascript" ></script>
<script src="/user/plugins/socialbuttons/vendor/rrssb/js/rrssb.min.js" type="text/javascript" ></script>

<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
"palette": {
    "popup": {
        "background": "#4d4d4d",
        "text": "#fff"
    },
    "button": {
        "background": "#f1d600",
        "text": "#000",
        "border": "#f1d600"
    }
},
"position": "bottom",
"theme": "block",
"content": {
    "message": "This website uses cookies to ensure you get the best experience on our website.",
    "dismiss": "Got it!",
    "link": "Learn more",
    "href": "https://cookiesandyou.com"
}
})});
hljs.initHighlightingOnLoad();

</script>


</head>
<body id="top" class="header-lite fullwidth blogstyling">
    <div id="sb-site">
                <header id="header">
                <div class="logo">
                    <h3><a href="https://iaml.it"><img src="/user/pages/images/IAML_logo_viola.png" /></a></h3>
                                            <ul class="social-icons">
            <li>
            <a href="https://twitter.com/iaml_it">
                <i class="fa fa-twitter"></i>            </a>
        </li>
            <li>
            <a href="https://www.linkedin.com/company/iaml/">
                <i class="fa fa-linkedin"></i>            </a>
        </li>
            <li>
            <a href="https://www.facebook.com/machinelearningitalia/">
                <i class="fa fa-facebook"></i>            </a>
        </li>
            <li>
            <a href="blog.rss">
                <i class="fa fa-rss"></i>            </a>
        </li>
    </ul>  
                                    </div>
                <div id="navbar">
                                                            
<ul class="navigation">
                                                        <li class="">
                    <a href="/">
                                                Home
                    </a>
                </li>
                                                                <li class="">
                    <a href="/activities">
                                                Activities
                    </a>
                </li>
                                                                <li class="">
                    <a href="/supporters">
                                                Supporters
                    </a>
                </li>
                                                                <li class="">
                    <a href="/member">
                                                Become a member
                    </a>
                </li>
                                                                <li class="active">
                    <a href="/blog">
                                                Blog
                    </a>
                </li>
                                                                <li class="">
                    <a href="/governance">
                                                Governance
                    </a>
                </li>
                                                                                                                                </ul>                                                   <form class="search-box">
    <input type="search" placeholder="Search..." value="" data-search-input="/search/query" />
    <script>
    jQuery(document).ready(function($){
        var input = $('[data-search-input]');

        input.on('keypress', function(event) {
            if (event.which == 13 && input.val().length > 3) {
                event.preventDefault();
                window.location.href = input.data('search-input') + ':' + input.val();
            }
        });
    });
    </script>
    <i class="fa fa-search"></i>
</form>                    <span class="panel-activation sb-toggle-left navbar-left menu-btn fa fa-bars"></span>
                </div>
        </header>
        
        
                <section id="body" class="">
                            
				<div class="flush-top blog-header blog-header-image" style="background: #B4B093 url(/user/pages/05.blog/blue_header.jpg) no-repeat right;">
            <h1>Introduzione alla Cluster Analysis</h1>
        </div>
            
        
<div id="breadcrumbs" itemscope itemtype="http://data-vocabulary.org/Breadcrumb">
                                            <a href="/" itemprop="url"><span itemprop="title">Home</span></a>
                        <i class="fa fa-angle-right"></i>
                                                <a href="/blog" itemprop="url"><span itemprop="title">Blog</span></a>
                        <i class="fa fa-angle-right"></i>
                                                <span itemprop="title">Introduzione alla Cluster Analysis</span>
                        </div>
		
		<div class="blog-content-item g-grid pure-g-r">
			<div id="item" class="g-block pure-u-2-3">
			    <div class="list-item">

    <div class="list-blog-header">
                    <img src="/images/3/c/0/e/9/3c0e9c4be56a5505bc334147be04d1d950dc51ff-0owdutc.png" />
        
                    <h4><a href="/blog/introduzione-cluster-analysis">Introduzione alla Cluster Analysis</a></h4>
        
        <span class="list-blog-date">
            <i class="fa fa-calendar"></i>
            05, Feb
        </span>
                <span class="list-blog-author">
            <i class="fa fa-user"></i>
            Stefano Di Pietro
        </span>
                       <ul class="tags">
            <i class="fa fa-tag"></i>
                        <li><a href="/blog/tag:clustering">clustering</a></li>
                        <li><a href="/blog/tag:analysis">analysis</a></li>
                        <li><a href="/blog/tag:kmeans">kmeans</a></li>
                    </ul>
        
    </div>

	<div>
	<br />
	<!-- AddToAny BEGIN -->
<div class="a2a_kit a2a_kit_size_32 a2a_default_style">
<a class="a2a_dd" href="https://www.addtoany.com/share"></a>
<a class="a2a_button_facebook"></a>
<a class="a2a_button_twitter"></a>
<a class="a2a_button_linkedin"></a>
<a class="a2a_button_google_plus"></a>
<a class="a2a_button_email"></a>
</div>
<script async src="https://static.addtoany.com/menu/page.js"></script>
<!-- AddToAny END -->
</div>
	
    <div class="list-blog-padding">

            <p><p>In questo articolo vengono descritti i concetti di base della <strong>Cluster Analysis</strong> ed alcuni tra gli algoritmi più importanti e rappresentativi delle tecniche principali ad oggi utilizzate. Lo scopo è quello di far comprendere la finalità della suddivisione in cluster ed i meccanismi che si celano dietro la loro costruzione.</p>
<p></p>
<nav class="table-of-contents minitoc" role="navigation">
                <span class="toctitle">Overview:</span>
      
                                                                                                    
  <ul>
      
        
        
              <li><a href="#le-origini" class="toclink" title="Le origini">Le origini</a></li>
      
        
        
              <li><a href="#cos--un-cluster" class="toclink" title="Cos’è un cluster?">Cos’è un cluster?</a></li>
      
        
        
              <li><a href="#clustering-vs-classification" class="toclink" title="Clustering vs Classification">Clustering vs Classification</a></li>
      
        
        
              <li><a href="#tecniche-di-clustering" class="toclink" title="Tecniche di clustering">Tecniche di clustering</a></li>
      
        
        
              <li><a href="#k-means" class="toclink" title="K-means">K-means</a></li>
      
                      <li><ul>
          
        
              <li><a href="#centroidi" class="toclink" title="Centroidi">Centroidi</a></li>
      
        
        
              <li><a href="#inizializzazione-dell-algoritmo..." class="toclink" title="Inizializzazione dell’algoritmo K-means">Inizializzazione dell’algoritmo K-means</a></li>
      
        
        
              <li><a href="#k-means-1" class="toclink" title="K-means++">K-means++</a></li>
      
        
        
              <li><a href="#esempio-di-utilizzo-del-k-means" class="toclink" title="Esempio di utilizzo del K-means">Esempio di utilizzo del K-means</a></li>
      
                      </ul></li>
          
        
              <li><a href="#quality-threshold-qt-clustering..." class="toclink" title="Quality Threshold (QT) clustering algorithm">Quality Threshold (QT) clustering algorithm</a></li>
      
        
        
              <li><a href="#clustering-gerarchico" class="toclink" title="Clustering gerarchico">Clustering gerarchico</a></li>
      
                      <li><ul>
          
        
              <li><a href="#tecnica-agglomerativa" class="toclink" title="Tecnica agglomerativa">Tecnica agglomerativa</a></li>
      
        
        
              <li><a href="#tecnica-divisiva" class="toclink" title="Tecnica divisiva">Tecnica divisiva</a></li>
      
                      </ul></li>
          
        
              <li><a href="#conclusioni" class="toclink" title="Conclusioni">Conclusioni</a></li>
      
    
  </ul>
</nav>


<h2 id="le-origini" class="headeranchor"><a class="headeranchor-link headeranchor-link--left headeranchor-visible--hover" aria-hidden="true" href="#le-origini" title="Permanent link: Le origini" data-icon="#">Le origini</a></h2>
<p>Quando Robert Tryon iniziò i suoi studi sulla psicologia comportamentale aveva forse sognato, come tutti i ricercatori, che almeno una delle sue teorie o idee potessero un giorno essere tramandate ai posteri. Nella fattispecie il suo studio sull’intelligenza come tratto genetico nei mammiferi ha, effettivamente, lasciato il segno nel campo della biologia, ma il suo metodo di analisi lo portò, forse involontariamente, a influenzare un ramo delle scienze matematiche oggi più che mai sulla cresta dell’onda: la statistica.
Robert Tryon, infatti, fu uno dei primi scienziati a utilizzare quello che lui chiamò la <strong>Cluster Analysis</strong>, la quale mantenne questo nome per i decenni a venire.</p>
<p>La Cluster Analysis è ad oggi uno degli strumenti più potenti e utilizzati tra quelli che pendono dalla cintura degli attrezzi di statistici e Data Scientist. Ma prima di spiegare in cosa consiste risponderemo ad una domanda che si pone spesso chi vi si imbatte per la prima volta.</p>
<h2 id="cos--un-cluster" class="headeranchor"><a class="headeranchor-link headeranchor-link--left headeranchor-visible--hover" aria-hidden="true" href="#cos--un-cluster" title="Permanent link: Cos’è un cluster?" data-icon="#">Cos’è un cluster?</a></h2>
<p>Per chi lavora nel campo dell'informatica (a prescindere dal ruolo) il termine cluster può far pensare a molte cose, ad esempio a un cluster di una rete di computer.
Il termine, di per sé, sta a indicare un <strong>raggruppamento</strong> di oggetti che hanno uno o più caratteristiche in comune.</p>
<p>Prendiamo ad esempio un insieme di individui.
Se di questi individui conosciamo unicamente il colore degli occhi, possiamo suddividere il gruppo in un numero di cluster pari al numero di colori. Quindi avremo un cluster contenente tutti gli individui con gli occhi azzurri, un altro contenente gli individui con gli occhi verdi e così via.</p>
<p>E’ possibile estendere questo ragionamento a un numero maggiore di attributi. Immaginiamo che ogni individuo nel nostro insieme indossi una maglietta rossa o blu.
Forti di questo nuovo attributo, possiamo creare una nuova suddivisione in cluster per raggruppare tutti gli individui con gli occhi azzurri e la maglietta rossa, gli occhi azzurri e la maglietta blu, gli occhi verdi e la maglietta rossa e così via.
Quindi, in sostanza, preso un insieme di oggetti aventi un certo numero di attributi, questi possono essere utilizzati per separare gli oggetti in un numero qualunque di cluster.</p>
<h2 id="clustering-vs-classification" class="headeranchor"><a class="headeranchor-link headeranchor-link--left headeranchor-visible--hover" aria-hidden="true" href="#clustering-vs-classification" title="Permanent link: Clustering vs Classification" data-icon="#">Clustering vs Classification</a></h2>
<p>Definito in questo modo il cluster assomiglia molto a un altro famoso membro della famiglia del Machine Learning: la classe.
Anche una classe raccoglie al suo interno una serie di oggetti aventi caratteristiche in comune;
la differenza sta principalmente nella tecnica utilizzata per definire di quale gruppo fa parte un determinato oggetto.</p>
<p>Quando si effettua una <strong>classificazione</strong> si hanno una serie di classi (categorie) note a priori e lo scopo è quello di capire a quale gruppo appartiene un oggetto osservando il valore dei suoi attributi.
Per fare questo, durante la fase di addestramento di un artefatto (modello) di classificazione, si parte da un insieme di oggetti dei quali si conosce già la categoria di appartenenza. Attraverso l’analisi degli attributi degli oggetti appartenenti a una determinata classe si cerca di trovare un pattern comune.
La classificazione è, quindi, un procedimento di <a href="https://en.wikipedia.org/wiki/Supervised_learning"><strong>apprendimento supervisionato</strong></a> dove la conoscenza di una determinata categoria esiste a prescindere dagli oggetti in essa raggruppabili.</p>
<p>Nella <strong>clusterizzazione</strong>, invece, si vuole estrapolare un certo numero di gruppi in cui è possibile separare gli oggetti di un insieme analizzando i valori dei loro attributi. In questo caso non esistono classi predeterminate né esempi che le rappresentino. L’algoritmo deve riuscire a identificare gli oggetti che "si somigliano" e raggrupparli tra loro.
Di conseguenza la clusterizzazione è un <a href="https://en.wikipedia.org/wiki/Unsupervised_learning"><strong>algoritmo di tipo non supervisionato</strong></a>.</p>
<h2 id="tecniche-di-clustering" class="headeranchor"><a class="headeranchor-link headeranchor-link--left headeranchor-visible--hover" aria-hidden="true" href="#tecniche-di-clustering" title="Permanent link: Tecniche di clustering" data-icon="#">Tecniche di clustering</a></h2>
<p>Un algoritmo di clustering è, quindi, in grado di raggruppare tra loro oggetti che hanno caratteristiche simili. <strong>Come riesce a raggiungere questo scopo?</strong></p>
<p>Esistono più tecniche che permettono di clusterizzare un insieme di oggetti. Una prima importante suddivisione dipende dalla tecnica di generazione dei cluster stessi, che divide gli algoritmi in due categorie:</p>
<ul>
<li><strong>Algoritmi di clusterizzazione agglomerativi</strong> (<em>bottom-up</em>)<br />
Iniziano inserendo ogni oggetto dell’insieme in un proprio cluster per poi raggrupparli iterativamente fino al raggiungimento di una condizione specifica (es. numero di cluster desiderato).</li>
<li><strong>Algoritmi di clusterizzazione divisivi</strong> (<em>top-down</em>)<br />
Iniziano inserendo tutti gli oggetti dell’insieme in un unico cluster per poi separarlo iterativamente in cluster più piccoli fino al raggiungimento di una condizione specifica.</li>
</ul>
<p>Il risultato finale, in entrambi i casi, è un insieme di cluster contenenti uno o più oggetti.</p>
<figure role="group">
        <img src="https://iaml.it/blog/introduzione-cluster-analysis/images/DxYx43X.png" />
        </figure>
<figcaption>Fig 1. Clusterizzazione agglomerativa.</figcaption>
<p></p>
<figure role="group">
        <img src="https://iaml.it/blog/introduzione-cluster-analysis/images/0OWDuTC.png" />
        </figure>
<figcaption>Fig 2. Clusterizzazione divisiva.</figcaption>
<p>A prescindere dall’approccio utilizzato, gli algoritmi di clustering si basano tutti su una <strong>metrica</strong>, puramente geometrica, che permetta di identificare quanto simili siano due oggetti fra di loro.
Infatti gli oggetti in esame vengono visti come insiemi di valori reali che ne rappresentano le caratteristiche (colore degli occhi, altezza, peso, ecc.). Questi valori, a loro volta, possono essere raggruppati in modo da formare dei <a href="https://en.wikipedia.org/wiki/Vector_(mathematics_and_physics)#Vectors_in_Euclidean_geometry">vettori</a> che rappresentino punti in uno spazio euclideo.</p>
<p>Tornando all’esempio della classificazione di individui consideriamo, questa volta, solamente l’altezza e il peso.
Immaginiamo che il nostro insieme sia composto dalle seguenti persone:</p>
<p><em>Han:</em> <br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Altezza: 180 cm<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Peso: 75 kg<br />
<em>Leia:</em><br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Altezza: 160 cm<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Peso: 50 kg<br />
<em>Chewbacca:</em><br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Altezza: 210 cm<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Peso:130 kg<br /></p>
<p>Se consideriamo l’altezza come prima coordinata ed il peso come seconda, questi tre individui possono essere rappresentati dai seguenti vettori e quindi visualizzabili in uno spazio euclideo (in questo caso di sole due dimensioni).</p>
<p>Han: (180, 75)<br />
Leia: (160, 50)<br />
Chewbacca: (210, 130)<br /></p>
<figure role="group">
        <img src="https://iaml.it/blog/introduzione-cluster-analysis/images/Zzw0X8E.png" />
        </figure>
<figcaption>Fig 3. Visualizzazione sul piano cartesiano di Leia, Han e Chewbacca in funzione dell’altezza e del peso.</figcaption>
<p>Maggiore è il numero degli attributi, maggiori saranno le dimensioni dello spazio in questione. Una volta che gli oggetti dell’insieme sono associati a punti nello spazio è possibile verificarne la "somiglianza" attraverso il concetto di <strong>distanza</strong>: più due punti sono vicini più saranno simili.</p>
<p>Le metriche principalmente utilizzate sono :</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Euclidean_distance">Distanza euclidea</a>.</li>
<li><a href="https://en.wikipedia.org/wiki/Taxicab_geometry">Distanza Manhattan</a>.</li>
<li><a href="https://en.wikipedia.org/wiki/Hamming_distance">Distanza di Hamming</a>.</li>
</ul>
<h2 id="k-means" class="headeranchor"><a class="headeranchor-link headeranchor-link--left headeranchor-visible--hover" aria-hidden="true" href="#k-means" title="Permanent link: K-means" data-icon="#">K-means</a></h2>
<p>L’algoritmo <strong>K-means</strong> è probabilmente la tecnica di clusterizzazione più famosa (ed un caso particolare dell’<a href="https://en.wikipedia.org/wiki/Lloyd's_algorithm">algoritmo di Lloyd</a>).</p>
<p>Il K-means è utilizzato in moltissimi campi, come la computer vision e la geostatistica, sia per la sua semplicità di implementazione che per le elevate performance che lo caratterizzano.
È un algoritmo di tipo iterativo che raffina la suddivisione degli oggetti a ogni ciclo e che si basa sul concetto di <strong>centroide</strong>.</p>
<h3 id="centroidi" class="headeranchor"><a class="headeranchor-link headeranchor-link--left headeranchor-visible--hover" aria-hidden="true" href="#centroidi" title="Permanent link: Centroidi" data-icon="#">Centroidi</a></h3>
<p>Un centroide è un punto nello spazio che rappresenta, sostanzialmente, un cluster e che corrisponde al punto medio dei punti del cluster stesso. Nell’esempio in Fig. 4 sono rappresentati due cluster con i rispettivi centroidi disegnati in rosso.</p>
<figure role="group">
        <img src="https://iaml.it/blog/introduzione-cluster-analysis/images/89r68xA.png" />
        </figure>
<figcaption>Fig 4. Cluster con relativi centroidi evidenziati in rosso.</figcaption>
<p>Da sottolineare il fatto che, anche se a volte, come vedremo più avanti, nella fase di costruzione dei cluster la posizione di un centroide può coincidere con quella di un oggetto, in generale <strong>il centroide non è un oggetto in essi contenuto</strong>.</p>
<p><strong>ALGORITMO K-MEANS (PSEUDOCODICE)</strong></p>
<p><strong>Input:</strong><br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="mathjax mathjax--inline">$N$</span> oggetti caratterizzati da vettori di dimensione <span class="mathjax mathjax--inline">$d$</span><br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Un intero <span class="mathjax mathjax--inline">$C$</span> che rappresenta il numero di cluster desiderati<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="mathjax mathjax--inline">$C$</span> vettori di dimensione d che rappresentano i centroidi rappresentativi dei cluster iniziali.<br /></p>
<p><strong>Repeat:</strong><br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Step 1 (<strong>Assignment</strong>):<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Assegna ogni oggetto al cluster il cui centroide ha la distanza euclidea più bassa (in sostanza il più vicino).<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Step 2 (<strong>Update</strong>):<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Per ogni cluster calcolare il punto medio delle osservazioni a esso associate; questo punto sarà il centroide di questo cluster per l’iterazione successiva.<br /></p>
<p>Il numero di iterazioni dipende dalla metodologia che si vuole adottare. È possibile decidere un numero fisso di iterazioni, oppure fare in modo che l’algoritmo esca dal ciclo subito dopo una iterazione nella quale nessun oggetto ha subito un cambiamento di cluster o quando si raggiunge un numero massimo di iterazioni.</p>
<h3 id="inizializzazione-dell-algoritmo..." class="headeranchor"><a class="headeranchor-link headeranchor-link--left headeranchor-visible--hover" aria-hidden="true" href="#inizializzazione-dell-algoritmo..." title="Permanent link: Inizializzazione dell’algoritmo K-means" data-icon="#">Inizializzazione dell’algoritmo K-means</a></h3>
<p>La scelta dei centroidi iniziali è un fattore che influenza molto il risultato finale, in quanto il K-means non garantisce il raggiungimento dell’ottimo globale (il miglior risultato possibile), ma può attestarsi in un punto di <strong>ottimo locale</strong>, ossia la configurazione di cluster migliore che gli è possibile raggiungere date le condizioni iniziali.</p>
<p>Due procedure tipiche sono scegliere degli oggetti dall’insieme da clusterizzare (<strong>Forgy method</strong>) oppure dei punti a caso nello spazio.
Un meccanismo ulteriore di inizializzazione, chiamato <strong>Random Partition</strong>, consiste nell’assegnare in maniera casuale ogni oggetto a un cluster per poi procedere con lo step di update, facendo in modo che i punti dei centroidi iniziali corrispondano con le medie degli oggetti assegnati.</p>
<h3 id="k-means-1" class="headeranchor"><a class="headeranchor-link headeranchor-link--left headeranchor-visible--hover" aria-hidden="true" href="#k-means-1" title="Permanent link: K-means++" data-icon="#">K-means++</a></h3>
<p>Nell'ambito della ricerca atta a migliorare le performance dell'algoritmo K-means, nel 2007 David Arthur e Sergei Vassilvitskii idearono <a href="http://ilpubs.stanford.edu:8090/778/1/2006-13.pdf">un metodo di inizializzazione</a> che chiamarono K-means++.
L'idea su cui si basa la loro tecnica consiste nel costruire un set di centroidi iniziali che siano il più "sparpagliati" possibile.</p>
<p><strong>ALGORITMO K-MEANS++ (PSEUDOCODICE)</strong></p>
<p><strong>Input:</strong><br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Un insieme <span class="mathjax mathjax--inline">$I$</span> di <span class="mathjax mathjax--inline">$N$</span> oggetti da clusterizzare<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Un intero <span class="mathjax mathjax--inline">$C$</span> che rappresenta il numero di cluster desiderati</p>
<p><strong>Repeat:</strong><br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>Step 1</strong>: Scegliere randomicamente un oggetto in <span class="mathjax mathjax--inline">$I$</span> ed eleggerlo a centroide<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Repeat <span class="mathjax mathjax--inline">$C-1$</span> times:<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>Step 2</strong>: Per ogni punto <span class="mathjax mathjax--inline">$i$</span> dell'insieme <span class="mathjax mathjax--inline">$I$</span> calcolare la distanza <span class="mathjax mathjax--inline">$D(i)$</span> dal centroide più vicino tra quelli costruiti fino a questo momento.<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>Step 3</strong>: Scegliere un punto <span class="mathjax mathjax--inline">$j$</span> in <span class="mathjax mathjax--inline">$I$</span> con una probabilità che sia proporzionale al quadrato della distanza <span class="mathjax mathjax--inline">$D(j)$</span> ed eleggerlo a centroide.</p>
<p>Questa procedura di inizializzazione ha dato risultati sorprendenti, dimostrando, in alcuni casi, di saper aumentare notevolmente le performance dell'algoritmo K-means, anche di svariati ordini di grandezza, oltre a raggiungere il risultato finale molto più velocemente.</p>
<h3 id="esempio-di-utilizzo-del-k-means" class="headeranchor"><a class="headeranchor-link headeranchor-link--left headeranchor-visible--hover" aria-hidden="true" href="#esempio-di-utilizzo-del-k-means" title="Permanent link: Esempio di utilizzo del K-means" data-icon="#">Esempio di utilizzo del K-means</a></h3>
<p>Nella prima delle figure in basso sono disegnati alcuni punti distribuiti in uno spazio a due dimensioni.</p>
<figure role="group">
        <img src="https://iaml.it/blog/introduzione-cluster-analysis/images/53vIwiU.png" />
        </figure>
<figcaption>Fig 5. Insieme di punti nello spazio cartesiano.</figcaption>
<p>A seguito della clusterizzazione tramite K-means i punti vengono suddivisi in cinque cluster, evidenziati in figura con colori diversi.</p>
<figure role="group">
        <img src="https://iaml.it/blog/introduzione-cluster-analysis/images/FOdKgQm.png" />
        </figure>
<figcaption>Fig 6. Suddivisione in 5 cluster tramite K-means.</figcaption>
<p>Modificando i parametri dell'algoritmo possiamo avere risultati diversi, infatti se decidiamo di generare solamente due cluster invece che cinque ricaveremo la situazione rappresentata nell'immagine sottostante.</p>
<figure role="group">
        <img src="https://iaml.it/blog/introduzione-cluster-analysis/images/IDp212l.png" />
        </figure>
<figcaption>Fig 7. Sudidvisione in 2 cluster tramite K-Means.</figcaption>
<div class="notices blue">
<p>È possibile visionare il codice usato per questo esempio sul notebook <a href="https://colab.research.google.com/drive/1GNb9tO_tt6e9ye6ALSEB_TIXos2RD8Oh">Colab</a> associato all'articolo.</p>
</div>
<p></p>
<h2 id="quality-threshold-qt-clustering..." class="headeranchor"><a class="headeranchor-link headeranchor-link--left headeranchor-visible--hover" aria-hidden="true" href="#quality-threshold-qt-clustering..." title="Permanent link: Quality Threshold (QT) clustering algorithm" data-icon="#">Quality Threshold (QT) clustering algorithm</a></h2>
<p>Mentre il K-means affonda le sue radici negli anni ‘60, l’algoritmo QT (Heyer et al., 1999) è di invenzione più recente ed è stato inizialmente utilizzato per l’analisi delle sequenze genetiche.
Al contrario del suo collega più anziano non richiede di specificare il numero di cluster da generare né un insieme iniziale di centroidi da cui partire.
Richiede invece in input una <strong>distanza soglia</strong> e un numero minimo di oggetti per cluster.
A ogni iterazione vengono costruiti una serie di cluster candidati, dei quali solamente uno sarà selezionato come vincitore. Il vincitore viene memorizzato per essere restituito al completamento del ciclo e i suoi punti rimossi prima dell’iterazione successiva.</p>
<p><strong>ALGORITMO QUALITY THRESHOLD (PSEUDOCODICE)</strong></p>
<p><strong>Input :</strong> <br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Distanza di soglia <span class="mathjax mathjax--inline">$D$</span>.<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Numero minimo di oggetti per cluster <span class="mathjax mathjax--inline">$m$</span>.<br /></p>
<p><strong>Repeat</strong>:<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Step 1: Per ogni oggetto dell’insieme si costruisce un cluster inserendovi, oltre all’oggetto in questione, anche tutti gli oggetti che hanno una distanza da questo inferiore a <span class="mathjax mathjax--inline">$D$</span>. Si costruisce così un insieme di cluster candidati.<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Step 2: Se non esiste nessun cluster che abbia un numero di oggetti superiore  a <span class="mathjax mathjax--inline">$m$</span> viene costruito un cluster per oggetto e l’algoritmo termina.<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Step 3: Dall’insieme di cluster candidati si sceglie quello con il numero maggiore di oggetti. Il cluster viene considerato vincitore e gli oggetti contenuti rimossi.</p>
<p>Per comprendere meglio lo step 1 si può fare riferimento alla Fig. 8 che rappresenta la fase in cui si sta analizzando il cluster candidato costruito attorno al punto 0.</p>
<figure role="group">
        <img src="https://iaml.it/blog/introduzione-cluster-analysis/images/HOfI3xx.png" />
        </figure>
<figcaption>Fig 8. Cerchio di raggio D che rappresenta l’area di cattura dei punti per la creazione del cluster candidato attorno al punto 0.</figcaption>
<p>La parte colorata in verde rappresenta l’area del cerchio che ha il punto 0 come centro e raggio <span class="mathjax mathjax--inline">$D$</span>.
In questo caso entrano a far parte del cluster candidato, oltre al punto 0 stesso, anche i punti 6, 8, e 5.
Vediamo cosa accade quando costruiamo il cluster candidato attorno al punto 4.</p>
<figure role="group">
        <img src="https://iaml.it/blog/introduzione-cluster-analysis/images/A5Yoacp.png" />
        </figure>
<figcaption>Fig 9. Cerchio di raggio D che rappresenta l’area di cattura dei punti per la creazione del cluster candidato attorno al punto 4.</figcaption>
<p>In questo caso i punti inclusi nel cluster sono 4, 6 e 8.
Avendo solamente 3 punti, contro i 4 del caso precedente, questo cluster non sarà sicuramente il vincitore di questa iterazione.</p>
<p>L’algoritmo descritto rende questo metodo un’alternativa al K-Means e i suoi derivati, che si distinguono per differenti metriche e tecniche di identificazione dei centroidi iniziali, ma mantengono il processo originale.
Ma, per quanto innovativa, l’idea di base del QT clustering, pur rendendolo un degno avversario del K-Means, non lo elegge a suo successore.
Infatti il QT clustering, anche se non richiede di indicare una ipotesi iniziale dei cluster, richiede comunque di indicare un numero minimo di oggetti che questi devono contenere e una distanza soglia.
Inoltre ha una <strong>maggiore complessità computazionale</strong> e risulta essere più lento: lentezza che aumenta con l’aumentare del numero di oggetti dell’insieme iniziale e del numero minimo di oggetti per cluster.
Nonostante questo, l’algoritmo QT ha un vantaggio rispetto al K-Means, e consiste nel fatto che, a ogni iterazione, vengono presi in considerazione tutti i cluster possibili (limitatamente ai vincoli imposti all’inizio dell’elaborazione).</p>
<p>Se prendiamo i punti disegnati in figura 5 e li clusterizziamo tramite l'algoritmo QT usando una distanza soglia di 3 e un numero minimo di 10 elementi per cluster avremo un risultato identico a quello in Fig. 6.</p>
<p>Anche in questo caso è possibile visionare un esempio di implementazione dell'algoritmo in Python sul notebook <a href="https://colab.research.google.com/drive/1GNb9tO_tt6e9ye6ALSEB_TIXos2RD8Oh">Colab</a> associato all'articolo.</p>
<h2 id="clustering-gerarchico" class="headeranchor"><a class="headeranchor-link headeranchor-link--left headeranchor-visible--hover" aria-hidden="true" href="#clustering-gerarchico" title="Permanent link: Clustering gerarchico" data-icon="#">Clustering gerarchico</a></h2>
<p>Il clustering gerarchico è un'altra tecnica di clusterizzazione nella quale invece di costruire semplicemente un insieme di cluster, come visto fino ad ora, viene costruita una gerarchia di cluster, rappresentabile tramite un <a href="https://en.wikipedia.org/wiki/Dendrogram">dendrogramma</a>.</p>
<figure role="group">
        <img src="https://iaml.it/blog/introduzione-cluster-analysis/images/FItV8Zo.png" />
        </figure>
<figcaption>Fig 10. Grafo a strati che rappresenta una possibile suddivisione gerarchica in cluster.</figcaption>
<p>In Fig. 10 si vede un esempio di clusterizzazione gerarchica.
Nel primo strato in alto gli oggetti sono tutti separati: per ognuno di essi esiste un cluster che li contiene in modo esclusivo. Questa configurazione rappresenta il caso in cui le regole di somiglianza tra i punti sono così ristrette che non esistono due punti che possano essere raggruppati nello stesso cluster.
Man mano che si scende verso i livelli più bassi alcuni cluster vengono a fondersi tra di loro diventando sempre più popolosi.
Effettuando un "taglio" ad una determinata altezza si ottiene una particolare configurazione di cluster: ad esempio se decidessimo di tagliare l'albero all'altezza dello strato D avremo tre cluster, mentre allo strato B ne avremo 5.
Come nel caso della clusterizzazione non gerarchica, anche qui esistono due tecniche di generazione dei cluster: <strong>agglomerativa</strong> (bottom-up) e <strong>divisiva</strong> (top-down). Inoltre, anche in questo caso, possono essere utilizzate diverse metriche per calcolare la distanza tra i punti e, in aggiunta, la distanza tra cluster (<strong>linkage criterion</strong>).</p>
<h3 id="tecnica-agglomerativa" class="headeranchor"><a class="headeranchor-link headeranchor-link--left headeranchor-visible--hover" aria-hidden="true" href="#tecnica-agglomerativa" title="Permanent link: Tecnica agglomerativa" data-icon="#">Tecnica agglomerativa</a></h3>
<p>Gli algoritmi di clusterizzazione gerarchica agglomerativi sono processi iterativi che, ad ogni iterazione, accorpano fra loro una coppia di cluster creandone così uno nuovo.
Un esempio di algoritmo di clusterizzazione agglomerativo è il <strong>single-linkage</strong> clustering, dove il termine single-linkage fa riferimento al linkage criterion utilizzato.
In questo algoritmo la distanza tra cluster corrisponde alla distanza minima fra due punti non appartenenti allo stesso cluster. A ogni iterazione i due cluster più vicini vengono fusi tra loro.
Osservando la Figira 10  è chiaro che l’algoritmo partirebbe quindi dallo strato A per poi scendere verso il basso.
Nell’implementazione di un algoritmo di clusterizzazione agglomerativa non è strettamente necessario tenere traccia degli attributi degli oggetti. Quello che spesso si fa è costruire una <strong>matrice delle distanze</strong>, dove ogni colonna e ogni riga corrispondono a un cluster. La matrice risultante è simmetrica rispetto alla diagonale, la quale ha tutti valori pari a zero.</p>
<table>
  <tr>
    <th></th>
    <th>A</th>
    <th>B</th>
    <th>C</th>
    <th>D</th>
  </tr>
  <tr>
    <td>A</td>
    <td>0</td>
    <td>0.3</td>
    <td>1.4</td>
    <td>2</td>
  </tr>
  <tr>
    <td>B</td>
    <td>-</td>
    <td>0</td>
    <td>2.9</td>
    <td>6</td>
  </tr>
  <tr>
    <td>C</td>
    <td>-</td>
    <td>-</td>
    <td>0</td>
    <td>0.7</td>
  </tr>
  <tr>
    <td>D</td>
    <td>-</td>
    <td>-</td>
    <td>-</td>
    <td>0</td>
  </tr>
</table>
<figcaption>Tab. 1. Esempio di matrice delle distanze tra punti.</figcaption>
<p>Nell’esempio nella Tab. 1 il cluster A ha una distanza di 1.4 dal cluster C.</p>
<p>Al termine di una iterazione, le righe e le colonne corrispondenti ai cluster che si sono uniti vengono fuse tra loro e le distanza ricalcolate.</p>
<figure role="group">
        <img src="https://iaml.it/blog/introduzione-cluster-analysis/images/jWOQn4L.png" />
        </figure>
<figcaption>Fig 11. Esempio di clusterizzazione di tipo agglomerativa.</figcaption>
<p>Sul notebook <a href="https://colab.research.google.com/drive/1GNb9tO_tt6e9ye6ALSEB_TIXos2RD8Oh">Colab</a> legato a questo articolo è possibile vedere un esempio di clusterizzazione agglomerativa con scikit-learn.</p>
<p>Altri algoritmi notevoli di clusterizzazione gerarchica agglomerativa sono:</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Complete-linkage_clustering">Complete-linkage clustering</a>.</li>
<li><a href="https://en.wikipedia.org/wiki/UPGMA">UPGMA</a>.</li>
<li>Minimum energy clustering (che utilizza la <a href="https://en.wikipedia.org/wiki/Energy_distance">Energy distance</a>). </li>
</ul>
<h3 id="tecnica-divisiva" class="headeranchor"><a class="headeranchor-link headeranchor-link--left headeranchor-visible--hover" aria-hidden="true" href="#tecnica-divisiva" title="Permanent link: Tecnica divisiva" data-icon="#">Tecnica divisiva</a></h3>
<p>Gli algoritmi di clusterizzazione gerarchici divisivi lavorano essenzialmente in maniera inversa rispetto a quelli agglomerativi. Di conseguenza lo stato di partenza è un unico cluster contenente tutti gli oggetti dell’insieme e, ad ogni iterazione, uno dei cluster viene diviso in due e i suoi oggetti distribuiti. Facendo riferimento alla Figura 10 l’algoritmo partirebbe dallo strato F per poi salire verso l’alto. La tecniche di selezione del cluster e di ripartizione degli oggetti sono specifiche di ogni implementazione.</p>
<figure role="group">
        <img src="https://iaml.it/blog/introduzione-cluster-analysis/images/U5aLymc.png" />
        </figure>
<figcaption>Fig 12. Esempio di clusterizzazione di tipo divisiva.</figcaption>
<h2 id="conclusioni" class="headeranchor"><a class="headeranchor-link headeranchor-link--left headeranchor-visible--hover" aria-hidden="true" href="#conclusioni" title="Permanent link: Conclusioni" data-icon="#">Conclusioni</a></h2>
<p>Esistono molte altre tecniche di clusterizzazione che non sono state toccate in questo articolo, nel quale ho cercato di dare una panoramica sugli algoritmi principali e sulle idee sulle quali si basano.
In un periodo nel quale gli algoritmi di machine learning supervisionato sono alla ribalta è importante ricordare che esistono molti altri strumenti ancora validi e fondamentali che sono di supporto all'analisi dei dati.</p>
<hr />
<p>Se questo articolo ti è piaciuto e vuoi tenerti aggiornato sulle nostre attività, ricordati che l'<a href="/member">iscrizione all'Italian Association for Machine Learning</a> è gratuita! Puoi seguirci su <a href="https://www.facebook.com/machinelearningitalia/">Facebook</a>, <a href="https://www.linkedin.com/company/iaml/">LinkedIn</a>, e <a href="https://twitter.com/iaml_it">Twitter</a>.</p></p>
            
    
        <p class="prev-next">
                            <a class="button" href="/blog/focus-on-in-codice-ratio"><i class="fa fa-chevron-left"></i> Previous Post</a>
            
                            <a class="button" href="/blog/differenziazione-automatica-parte-1">Next Post <i class="fa fa-chevron-right"></i></a>
                    </p>
    
    </div>
</div>
			</div>
			<div id="sidebar" class="g-block size-1-3 pure-u-1-3">
				<div class="sidebar-content">
    <h4>Search the blog</h4>
    <input type="text" placeholder="Search..." value="" data-searchsidebar-input="/search/query" />
<script>
jQuery(document).ready(function($){
    var input = $('[data-searchsidebar-input]');

    input.on('keypress', function(event) {
        if (event.which == 13 && input.val().length > 3) {
            event.preventDefault();
            window.location.href = input.data('searchsidebar-input') + ':' + input.val();
        }
    });
});
</script>
</div>
<!--
<div class="sidebar-content">
	<h4>Some Text Widget</h4>
	<p>Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna.</p>
</div>
!-->
<div class="sidebar-content">
    <h4>Categories</h4>
    

<ul class="archives">
        <li>
        <a href="/blog/category:Tutorials">Tutorials </a> (16)
    </li>
        <li>
        <a href="/blog/category:Discussions">Discussions </a> (12)
    </li>
        <li>
        <a href="/blog/category:Announcements">Announcements </a> (4)
    </li>
        <li>
        <a href="/blog/category:Tutorials%20%28English%29">Tutorials (English) </a> (4)
    </li>
        <li>
        <a href="/blog/category:Articles%27%20summaries">Articles' summaries </a> (3)
    </li>
        <li>
        <a href="/blog/category:Discussions%20%28English%29">Discussions (English) </a> (2)
    </li>
        <li>
        <a href="/blog/category:Focus-on">Focus-on </a> (1)
    </li>
        <li>
        <a href="/blog/category:Reviews">Reviews </a> (1)
    </li>
        <li>
        <a href="/blog/category:Discussion">Discussion </a> (1)
    </li>
    </ul>
</div>
<div class="sidebar-content">
    <h4>Archives</h4>
	<ul class="archives">
    <li>
    	<a href="/blog/archives_month:apr_2020">
        <span class="archive_date">April 2020</span>
                <span>(1)</span>
                </a>
    </li>
</ul>
</div>
<div class="sidebar-content">
    <h4>Popular Tags</h4>
    

<ul class="archives">
        <li>
        <a href="/blog/tag:deep%20learning">deep learning </a> (11)
    </li>
        <li>
        <a href="/blog/tag:pytorch">pytorch </a> (9)
    </li>
        <li>
        <a href="/blog/tag:reti%20neurali">reti neurali </a> (5)
    </li>
        <li>
        <a href="/blog/tag:google">google </a> (4)
    </li>
        <li>
        <a href="/blog/tag:jit">jit </a> (4)
    </li>
        <li>
        <a href="/blog/tag:tensorflow">tensorflow </a> (4)
    </li>
        <li>
        <a href="/blog/tag:ottimizzazione">ottimizzazione </a> (4)
    </li>
        <li>
        <a href="/blog/tag:rete%20neurale">rete neurale </a> (3)
    </li>
        <li>
        <a href="/blog/tag:time%20series">time series </a> (3)
    </li>
        <li>
        <a href="/blog/tag:keras">keras </a> (3)
    </li>
        <li>
        <a href="/blog/tag:reti%20convolutive">reti convolutive </a> (3)
    </li>
        <li>
        <a href="/blog/tag:pipeline">pipeline </a> (2)
    </li>
        <li>
        <a href="/blog/tag:sklearn">sklearn </a> (2)
    </li>
        <li>
        <a href="/blog/tag:autodiff">autodiff </a> (2)
    </li>
        <li>
        <a href="/blog/tag:automatic%20differentation">automatic differentation </a> (2)
    </li>
        <li>
        <a href="/blog/tag:reverse-mode">reverse-mode </a> (2)
    </li>
        <li>
        <a href="/blog/tag:derivate">derivate </a> (2)
    </li>
        <li>
        <a href="/blog/tag:differenziazione">differenziazione </a> (2)
    </li>
        <li>
        <a href="/blog/tag:model%20selection">model selection </a> (2)
    </li>
        <li>
        <a href="/blog/tag:cross%20validation">cross validation </a> (2)
    </li>
        <li>
        <a href="/blog/tag:c%2B%2B">c++ </a> (2)
    </li>
        <li>
        <a href="/blog/tag:numpy">numpy </a> (2)
    </li>
        <li>
        <a href="/blog/tag:vmap">vmap </a> (2)
    </li>
        <li>
        <a href="/blog/tag:caffe">caffe </a> (2)
    </li>
        <li>
        <a href="/blog/tag:compiler">compiler </a> (2)
    </li>
        <li>
        <a href="/blog/tag:jax">jax </a> (2)
    </li>
        <li>
        <a href="/blog/tag:codemotion">codemotion </a> (1)
    </li>
        <li>
        <a href="/blog/tag:bias">bias </a> (1)
    </li>
        <li>
        <a href="/blog/tag:discrimination">discrimination </a> (1)
    </li>
        <li>
        <a href="/blog/tag:fairness">fairness </a> (1)
    </li>
        <li>
        <a href="/blog/tag:iaml">iaml </a> (1)
    </li>
        <li>
        <a href="/blog/tag:database">database </a> (1)
    </li>
        <li>
        <a href="/blog/tag:iperparametri">iperparametri </a> (1)
    </li>
        <li>
        <a href="/blog/tag:autograph">autograph </a> (1)
    </li>
        <li>
        <a href="/blog/tag:head">head </a> (1)
    </li>
        <li>
        <a href="/blog/tag:multi-task">multi-task </a> (1)
    </li>
        <li>
        <a href="/blog/tag:learning">learning </a> (1)
    </li>
        <li>
        <a href="/blog/tag:novit%C3%A0">novità </a> (1)
    </li>
        <li>
        <a href="/blog/tag:dev%20summit">dev summit </a> (1)
    </li>
        <li>
        <a href="/blog/tag:custom%20estimator">custom estimator </a> (1)
    </li>
        <li>
        <a href="/blog/tag:hyperopt">hyperopt </a> (1)
    </li>
        <li>
        <a href="/blog/tag:goodfellow">goodfellow </a> (1)
    </li>
        <li>
        <a href="/blog/tag:nlp">nlp </a> (1)
    </li>
        <li>
        <a href="/blog/tag:dati%20mancanti">dati mancanti </a> (1)
    </li>
        <li>
        <a href="/blog/tag:transformer">transformer </a> (1)
    </li>
        <li>
        <a href="/blog/tag:attenzione">attenzione </a> (1)
    </li>
        <li>
        <a href="/blog/tag:robocop">robocop </a> (1)
    </li>
        <li>
        <a href="/blog/tag:yolo">yolo </a> (1)
    </li>
        <li>
        <a href="/blog/tag:object%20detection">object detection </a> (1)
    </li>
        <li>
        <a href="/blog/tag:bayes">bayes </a> (1)
    </li>
        <li>
        <a href="/blog/tag:autoencoders">autoencoders </a> (1)
    </li>
        <li>
        <a href="/blog/tag:variational">variational </a> (1)
    </li>
        <li>
        <a href="/blog/tag:eager">eager </a> (1)
    </li>
        <li>
        <a href="/blog/tag:imputazione">imputazione </a> (1)
    </li>
        <li>
        <a href="/blog/tag:CIFAR">CIFAR </a> (1)
    </li>
        <li>
        <a href="/blog/tag:word%20embedding">word embedding </a> (1)
    </li>
        <li>
        <a href="/blog/tag:MNIST">MNIST </a> (1)
    </li>
        <li>
        <a href="/blog/tag:immagini">immagini </a> (1)
    </li>
        <li>
        <a href="/blog/tag:classificazione">classificazione </a> (1)
    </li>
        <li>
        <a href="/blog/tag:kpi">kpi </a> (1)
    </li>
        <li>
        <a href="/blog/tag:reprogramming">reprogramming </a> (1)
    </li>
        <li>
        <a href="/blog/tag:adversarial">adversarial </a> (1)
    </li>
        <li>
        <a href="/blog/tag:browser">browser </a> (1)
    </li>
        <li>
        <a href="/blog/tag:javascript">javascript </a> (1)
    </li>
        <li>
        <a href="/blog/tag:reti%20ricorsive">reti ricorsive </a> (1)
    </li>
        <li>
        <a href="/blog/tag:reti%20ricorrenti">reti ricorrenti </a> (1)
    </li>
        <li>
        <a href="/blog/tag:ftth">ftth </a> (1)
    </li>
        <li>
        <a href="/blog/tag:adversarial%20example">adversarial example </a> (1)
    </li>
        <li>
        <a href="/blog/tag:management">management </a> (1)
    </li>
        <li>
        <a href="/blog/tag:robotica">robotica </a> (1)
    </li>
        <li>
        <a href="/blog/tag:ocr">ocr </a> (1)
    </li>
        <li>
        <a href="/blog/tag:focus">focus </a> (1)
    </li>
        <li>
        <a href="/blog/tag:iphone">iphone </a> (1)
    </li>
        <li>
        <a href="/blog/tag:python">python </a> (1)
    </li>
        <li>
        <a href="/blog/tag:face%20id">face id </a> (1)
    </li>
        <li>
        <a href="/blog/tag:momento">momento </a> (1)
    </li>
        <li>
        <a href="/blog/tag:adam">adam </a> (1)
    </li>
        <li>
        <a href="/blog/tag:neuroscienza">neuroscienza </a> (1)
    </li>
        <li>
        <a href="/blog/tag:onde%20cerebrali">onde cerebrali </a> (1)
    </li>
        <li>
        <a href="/blog/tag:torchvision">torchvision </a> (1)
    </li>
        <li>
        <a href="/blog/tag:latin">latin </a> (1)
    </li>
        <li>
        <a href="/blog/tag:pretrained">pretrained </a> (1)
    </li>
        <li>
        <a href="/blog/tag:rete%20convolutiva">rete convolutiva </a> (1)
    </li>
        <li>
        <a href="/blog/tag:autograd">autograd </a> (1)
    </li>
        <li>
        <a href="/blog/tag:swish">swish </a> (1)
    </li>
        <li>
        <a href="/blog/tag:attivazione">attivazione </a> (1)
    </li>
        <li>
        <a href="/blog/tag:checkpoint">checkpoint </a> (1)
    </li>
        <li>
        <a href="/blog/tag:tensori">tensori </a> (1)
    </li>
        <li>
        <a href="/blog/tag:variabili">variabili </a> (1)
    </li>
        <li>
        <a href="/blog/tag:lineare">lineare </a> (1)
    </li>
        <li>
        <a href="/blog/tag:regressione">regressione </a> (1)
    </li>
        <li>
        <a href="/blog/tag:convolutional%20networks">convolutional networks </a> (1)
    </li>
        <li>
        <a href="/blog/tag:Vatican">Vatican </a> (1)
    </li>
        <li>
        <a href="/blog/tag:project">project </a> (1)
    </li>
        <li>
        <a href="/blog/tag:kernel">kernel </a> (1)
    </li>
        <li>
        <a href="/blog/tag:ICLR">ICLR </a> (1)
    </li>
        <li>
        <a href="/blog/tag:ipotesi">ipotesi </a> (1)
    </li>
        <li>
        <a href="/blog/tag:sparsit%C3%A0">sparsità </a> (1)
    </li>
        <li>
        <a href="/blog/tag:funzionale">funzionale </a> (1)
    </li>
        <li>
        <a href="/blog/tag:functional">functional </a> (1)
    </li>
        <li>
        <a href="/blog/tag:adversarial%20attack">adversarial attack </a> (1)
    </li>
        <li>
        <a href="/blog/tag:kmeans">kmeans </a> (1)
    </li>
        <li>
        <a href="/blog/tag:analysis">analysis </a> (1)
    </li>
        <li>
        <a href="/blog/tag:clustering">clustering </a> (1)
    </li>
        <li>
        <a href="/blog/tag:Google">Google </a> (1)
    </li>
        <li>
        <a href="/blog/tag:regression">regression </a> (1)
    </li>
        <li>
        <a href="/blog/tag:JAX">JAX </a> (1)
    </li>
        <li>
        <a href="/blog/tag:gaussian%20process">gaussian process </a> (1)
    </li>
        <li>
        <a href="/blog/tag:ensemble">ensemble </a> (1)
    </li>
        <li>
        <a href="/blog/tag:boosting">boosting </a> (1)
    </li>
        <li>
        <a href="/blog/tag:gradient">gradient </a> (1)
    </li>
        <li>
        <a href="/blog/tag:semi-supervised%20learning">semi-supervised learning </a> (1)
    </li>
        <li>
        <a href="/blog/tag:document%20classification">document classification </a> (1)
    </li>
        <li>
        <a href="/blog/tag:graphs">graphs </a> (1)
    </li>
        <li>
        <a href="/blog/tag:variables">variables </a> (1)
    </li>
        <li>
        <a href="/blog/tag:linear">linear </a> (1)
    </li>
        <li>
        <a href="/blog/tag:k-NN">k-NN </a> (1)
    </li>
    </ul>
</div>
<div class="sidebar-content syndicate">
    <h4>Syndicate</h4>
    <a class="button" href="/blog.atom"><i class="fa fa-rss-square"></i> Atom 1.0</a>
    <a class="button" href="/blog.rss"><i class="fa fa-rss-square"></i> RSS</a>
</div>
			</div>
		</div>
	
                        <div class="modular-row footer ">
    <div class="footer-items">
        <div class="footer-module large">
		<h4>About</h4>
                            <p>Italian Association for Machine Learning (C.F. 97949550582)</p>
            			<p>Write us: info@iaml.it</p>
        </div>
        <div class="footer-module"><h4>Address</h4>
            <p>
                                    <span><strong>Operational office</strong></span>
                                    <span>IAML c/o Pi Campus, via Indonesia 23, 00144 Rome</span>
                                    <span><strong>Legal office</strong></span>
                                    <span>Via Cassia 964, 00189, Rome</span>
                            </p>
        </div>
        <div class="footer-module"><h4>Quick Links</h4>
         <ul class="quickmenu">
                            <li><i class="fa fa-chevron-right"></i><a href="https://iaml.it/home">Home</a></li>
                            <li><i class="fa fa-chevron-right"></i><a href="https://iaml.it/documents">Documents (Italian)</a></li>
                    </ul>
    </div>
   
</div>
<hr>
<div class="footer-modules">
    <div class="footer-copyright">
        Copyright 2018 IAML.IT. All Rights Reserved.
    </div>
    <div class="footer-menu">
    <ul class="othermenu">
           <li><a href="https://learn.getgrav.org/">Powered by Grav</a></li>
           <li><a href="https://github.com/getgrav/grav-theme-deliver">Theme (adapted) from Deliver</a></li>
        </ul>
    </div>
</div>
</div>                    </section>
        
    </div>
    <div class="sb-slidebar sb-left sb-width-thin">
        <div id="panel">
        
<ul class="navigation">
                                                        <li class="">
                    <a href="/">
                                                Home
                    </a>
                </li>
                                                                <li class="">
                    <a href="/activities">
                                                Activities
                    </a>
                </li>
                                                                <li class="">
                    <a href="/supporters">
                                                Supporters
                    </a>
                </li>
                                                                <li class="">
                    <a href="/member">
                                                Become a member
                    </a>
                </li>
                                                                <li class="active">
                    <a href="/blog">
                                                Blog
                    </a>
                </li>
                                                                <li class="">
                    <a href="/governance">
                                                Governance
                    </a>
                </li>
                                                                                                                                </ul>                   </div>
    </div>
        <script src="/user/plugins/simplesearch/js/simplesearch.js" type="text/javascript" ></script>

    <script>
    $(function () {
        $(document).ready(function() {
          $.slidebars({
            hideControlClasses: true,
            scrollLock: true
          });
        });
    });
    </script>
    </body>
</html>
